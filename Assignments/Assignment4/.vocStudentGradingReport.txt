
[Executed at: Mon Nov 20 21:47:50 PST 2023]

==================================================
Task 1 (python) runtime (ms), 380745
Task 1: 2.0 out of 2
==================================================
Task 2 (python) runtime (ms), 25376
Task 2.1: 2.0 out of 2
Task 2.2: 3.0 out of 3
==================================================
task1.scala not found
Task 1(Scala) runtime (ms), 8
Task 1 Scala: 0.0
==================================================
task2.scala not found
Task 2 (Scala) runtime (ms), 2
Task 2.1 Scala:  0.0
Task 2.2 Scala:  0.0
==================================================

23/11/20 21:40:54 WARN Utils: Your hostname, ip-172-31-32-254 resolves to a loopback address: 127.0.0.1; using 172.31.32.254 instead (on interface ens5)
23/11/20 21:40:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
:: loading settings :: url = jar:file:/opt/spark/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /home/eee_G_2643284/.ivy2/cache
The jars for the packages stored in: /home/eee_G_2643284/.ivy2/jars
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-0cc434be-e06d-49c5-8960-18d1166858f3;1.0
	confs: [default]
	found graphframes#graphframes;0.8.2-spark3.1-s_2.12 in spark-list
	found org.slf4j#slf4j-api;1.7.16 in central
:: resolution report :: resolve 608ms :: artifacts dl 18ms
	:: modules in use:
	graphframes#graphframes;0.8.2-spark3.1-s_2.12 from spark-list in [default]
	org.slf4j#slf4j-api;1.7.16 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-0cc434be-e06d-49c5-8960-18d1166858f3
	confs: [default]
	0 artifacts copied, 2 already retrieved (0kB/7ms)
23/11/20 21:40:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
23/11/20 21:41:05 INFO SparkContext: Running Spark version 3.1.2
23/11/20 21:41:05 INFO ResourceUtils: ==============================================================
23/11/20 21:41:05 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/20 21:41:05 INFO ResourceUtils: ==============================================================
23/11/20 21:41:05 INFO SparkContext: Submitted application: CommunityDetection
23/11/20 21:41:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/20 21:41:05 INFO ResourceProfile: Limiting resource is cpu
23/11/20 21:41:05 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/20 21:41:05 INFO SecurityManager: Changing view acls to: eee_G_2643284
23/11/20 21:41:05 INFO SecurityManager: Changing modify acls to: eee_G_2643284
23/11/20 21:41:05 INFO SecurityManager: Changing view acls groups to: 
23/11/20 21:41:05 INFO SecurityManager: Changing modify acls groups to: 
23/11/20 21:41:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eee_G_2643284); groups with view permissions: Set(); users  with modify permissions: Set(eee_G_2643284); groups with modify permissions: Set()
23/11/20 21:41:06 INFO Utils: Successfully started service 'sparkDriver' on port 43185.
23/11/20 21:41:06 INFO SparkEnv: Registering MapOutputTracker
23/11/20 21:41:06 INFO SparkEnv: Registering BlockManagerMaster
23/11/20 21:41:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/20 21:41:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/20 21:41:06 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/20 21:41:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-39e05336-3987-4373-b195-3ac3b054e82a
23/11/20 21:41:06 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/11/20 21:41:06 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/20 21:41:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/11/20 21:41:06 INFO Utils: Successfully started service 'SparkUI' on port 4041.
23/11/20 21:41:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.31.32.254:4041
23/11/20 21:41:07 INFO SparkContext: Added JAR file:///home/eee_G_2643284/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar at spark://172.31.32.254:43185/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar with timestamp 1700545265300
23/11/20 21:41:07 INFO SparkContext: Added JAR file:///home/eee_G_2643284/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://172.31.32.254:43185/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1700545265300
23/11/20 21:41:07 INFO SparkContext: Added file file:///home/eee_G_2643284/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar at file:///home/eee_G_2643284/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar with timestamp 1700545265300
23/11/20 21:41:07 INFO Utils: Copying /home/eee_G_2643284/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar to /tmp/spark-0f9ecc6c-1b47-4039-ab9f-3594766462ba/userFiles-5ee35304-61de-420d-a22b-765f1baab7e7/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar
23/11/20 21:41:07 INFO SparkContext: Added file file:///home/eee_G_2643284/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at file:///home/eee_G_2643284/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1700545265300
23/11/20 21:41:07 INFO Utils: Copying /home/eee_G_2643284/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-0f9ecc6c-1b47-4039-ab9f-3594766462ba/userFiles-5ee35304-61de-420d-a22b-765f1baab7e7/org.slf4j_slf4j-api-1.7.16.jar
23/11/20 21:41:07 INFO Executor: Starting executor ID driver on host 172.31.32.254
23/11/20 21:41:07 INFO Executor: Fetching file:///home/eee_G_2643284/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1700545265300
23/11/20 21:41:07 INFO Utils: /home/eee_G_2643284/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar has been previously copied to /tmp/spark-0f9ecc6c-1b47-4039-ab9f-3594766462ba/userFiles-5ee35304-61de-420d-a22b-765f1baab7e7/org.slf4j_slf4j-api-1.7.16.jar
23/11/20 21:41:07 INFO Executor: Fetching file:///home/eee_G_2643284/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar with timestamp 1700545265300
23/11/20 21:41:07 INFO Utils: /home/eee_G_2643284/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar has been previously copied to /tmp/spark-0f9ecc6c-1b47-4039-ab9f-3594766462ba/userFiles-5ee35304-61de-420d-a22b-765f1baab7e7/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar
23/11/20 21:41:07 INFO Executor: Fetching spark://172.31.32.254:43185/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar with timestamp 1700545265300
23/11/20 21:41:07 INFO TransportClientFactory: Successfully created connection to /172.31.32.254:43185 after 72 ms (0 ms spent in bootstraps)
23/11/20 21:41:07 INFO Utils: Fetching spark://172.31.32.254:43185/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar to /tmp/spark-0f9ecc6c-1b47-4039-ab9f-3594766462ba/userFiles-5ee35304-61de-420d-a22b-765f1baab7e7/fetchFileTemp16637680908581923112.tmp
23/11/20 21:41:07 INFO Utils: /tmp/spark-0f9ecc6c-1b47-4039-ab9f-3594766462ba/userFiles-5ee35304-61de-420d-a22b-765f1baab7e7/fetchFileTemp16637680908581923112.tmp has been previously copied to /tmp/spark-0f9ecc6c-1b47-4039-ab9f-3594766462ba/userFiles-5ee35304-61de-420d-a22b-765f1baab7e7/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar
23/11/20 21:41:07 INFO Executor: Adding file:/tmp/spark-0f9ecc6c-1b47-4039-ab9f-3594766462ba/userFiles-5ee35304-61de-420d-a22b-765f1baab7e7/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar to class loader
23/11/20 21:41:07 INFO Executor: Fetching spark://172.31.32.254:43185/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1700545265300
23/11/20 21:41:07 INFO Utils: Fetching spark://172.31.32.254:43185/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-0f9ecc6c-1b47-4039-ab9f-3594766462ba/userFiles-5ee35304-61de-420d-a22b-765f1baab7e7/fetchFileTemp5858146094429963483.tmp
23/11/20 21:41:07 INFO Utils: /tmp/spark-0f9ecc6c-1b47-4039-ab9f-3594766462ba/userFiles-5ee35304-61de-420d-a22b-765f1baab7e7/fetchFileTemp5858146094429963483.tmp has been previously copied to /tmp/spark-0f9ecc6c-1b47-4039-ab9f-3594766462ba/userFiles-5ee35304-61de-420d-a22b-765f1baab7e7/org.slf4j_slf4j-api-1.7.16.jar
23/11/20 21:41:07 INFO Executor: Adding file:/tmp/spark-0f9ecc6c-1b47-4039-ab9f-3594766462ba/userFiles-5ee35304-61de-420d-a22b-765f1baab7e7/org.slf4j_slf4j-api-1.7.16.jar to class loader
23/11/20 21:41:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42127.
23/11/20 21:41:07 INFO NettyBlockTransferService: Server created on 172.31.32.254:42127
23/11/20 21:41:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/20 21:41:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.31.32.254, 42127, None)
23/11/20 21:41:07 INFO BlockManagerMasterEndpoint: Registering block manager 172.31.32.254:42127 with 434.4 MiB RAM, BlockManagerId(driver, 172.31.32.254, 42127, None)
23/11/20 21:41:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.31.32.254, 42127, None)
23/11/20 21:41:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.31.32.254, 42127, None)
Duration:  339.7915828227997
23/11/20 21:46:53 WARN Utils: Your hostname, ip-172-31-32-254 resolves to a loopback address: 127.0.0.1; using 172.31.32.254 instead (on interface ens5)
23/11/20 21:46:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
23/11/20 21:46:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
23/11/20 21:46:55 INFO SparkContext: Running Spark version 3.1.2
23/11/20 21:46:55 INFO ResourceUtils: ==============================================================
23/11/20 21:46:55 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/20 21:46:55 INFO ResourceUtils: ==============================================================
23/11/20 21:46:55 INFO SparkContext: Submitted application: CommunityDetection
23/11/20 21:46:55 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/20 21:46:55 INFO ResourceProfile: Limiting resource is cpu
23/11/20 21:46:55 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/20 21:46:55 INFO SecurityManager: Changing view acls to: eee_G_2643284
23/11/20 21:46:55 INFO SecurityManager: Changing modify acls to: eee_G_2643284
23/11/20 21:46:55 INFO SecurityManager: Changing view acls groups to: 
23/11/20 21:46:55 INFO SecurityManager: Changing modify acls groups to: 
23/11/20 21:46:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eee_G_2643284); groups with view permissions: Set(); users  with modify permissions: Set(eee_G_2643284); groups with modify permissions: Set()
23/11/20 21:46:55 INFO Utils: Successfully started service 'sparkDriver' on port 45136.
23/11/20 21:46:56 INFO SparkEnv: Registering MapOutputTracker
23/11/20 21:46:56 INFO SparkEnv: Registering BlockManagerMaster
23/11/20 21:46:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/20 21:46:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/20 21:46:56 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/20 21:46:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-73d58888-b852-4e94-8614-7c9ce8310054
23/11/20 21:46:56 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/11/20 21:46:56 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/20 21:46:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/11/20 21:46:56 INFO Utils: Successfully started service 'SparkUI' on port 4041.
23/11/20 21:46:56 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.31.32.254:4041
23/11/20 21:46:56 INFO Executor: Starting executor ID driver on host 172.31.32.254
23/11/20 21:46:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41697.
23/11/20 21:46:56 INFO NettyBlockTransferService: Server created on 172.31.32.254:41697
23/11/20 21:46:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/20 21:46:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.31.32.254, 41697, None)
23/11/20 21:46:56 INFO BlockManagerMasterEndpoint: Registering block manager 172.31.32.254:41697 with 434.4 MiB RAM, BlockManagerId(driver, 172.31.32.254, 41697, None)
23/11/20 21:46:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.31.32.254, 41697, None)
23/11/20 21:46:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.31.32.254, 41697, None)
Duration:  19.70074772834778
23/11/20 21:47:18 WARN Utils: Your hostname, ip-172-31-32-254 resolves to a loopback address: 127.0.0.1; using 172.31.32.254 instead (on interface ens5)
23/11/20 21:47:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
23/11/20 21:47:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
23/11/20 21:47:20 INFO SparkContext: Running Spark version 3.1.2
23/11/20 21:47:20 INFO ResourceUtils: ==============================================================
23/11/20 21:47:20 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/20 21:47:20 INFO ResourceUtils: ==============================================================
23/11/20 21:47:20 INFO SparkContext: Submitted application: CommunityDetection
23/11/20 21:47:20 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/20 21:47:20 INFO ResourceProfile: Limiting resource is cpu
23/11/20 21:47:20 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/20 21:47:20 INFO SecurityManager: Changing view acls to: eee_G_2643284
23/11/20 21:47:20 INFO SecurityManager: Changing modify acls to: eee_G_2643284
23/11/20 21:47:20 INFO SecurityManager: Changing view acls groups to: 
23/11/20 21:47:20 INFO SecurityManager: Changing modify acls groups to: 
23/11/20 21:47:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eee_G_2643284); groups with view permissions: Set(); users  with modify permissions: Set(eee_G_2643284); groups with modify permissions: Set()
23/11/20 21:47:20 INFO Utils: Successfully started service 'sparkDriver' on port 33079.
23/11/20 21:47:20 INFO SparkEnv: Registering MapOutputTracker
23/11/20 21:47:20 INFO SparkEnv: Registering BlockManagerMaster
23/11/20 21:47:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/20 21:47:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/20 21:47:20 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/20 21:47:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5c2cbc6c-9e75-41bf-bb86-92f08727b69f
23/11/20 21:47:20 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/11/20 21:47:21 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/20 21:47:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/11/20 21:47:21 INFO Utils: Successfully started service 'SparkUI' on port 4041.
23/11/20 21:47:21 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.31.32.254:4041
23/11/20 21:47:21 INFO Executor: Starting executor ID driver on host 172.31.32.254
23/11/20 21:47:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33536.
23/11/20 21:47:21 INFO NettyBlockTransferService: Server created on 172.31.32.254:33536
23/11/20 21:47:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/20 21:47:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.31.32.254, 33536, None)
23/11/20 21:47:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.31.32.254:33536 with 434.4 MiB RAM, BlockManagerId(driver, 172.31.32.254, 33536, None)
23/11/20 21:47:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.31.32.254, 33536, None)
23/11/20 21:47:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.31.32.254, 33536, None)
Duration:  17.463304042816162
